{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Current device  >>  cuda\n",
      "=========================== \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./..')\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./../../..')\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor as FT\n",
    "from torch import LongTensor as LT\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions.normal import Normal\n",
    "import math\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import yaml\n",
    "try:\n",
    "    from data_fetcher import data_fetcher\n",
    "except:\n",
    "    from .data_fetcher import data_fetcher\n",
    "\n",
    "\n",
    "from  model_dcn import DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device  >>  cuda:2\n",
      "=========================== \n"
     ]
    }
   ],
   "source": [
    "    \n",
    "EPSILON = math.pow(10, -6)\n",
    "DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print('Current device  >> ', DEVICE)\n",
    "print('=========================== ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    DATA_SET,\n",
    "    data_dict,\n",
    "    config\n",
    "):\n",
    "    global DEVICE\n",
    "    print('DEVICE ',DEVICE)\n",
    "    layer_dims = config[DATA_SET]['layer_dims']\n",
    "    train_df = data_dict['train']\n",
    "    train_X = train_df.values\n",
    "    data_dim = train_X.shape[1]\n",
    "\n",
    "    epochs_1 = config[DATA_SET]['epochs_1']\n",
    "    epochs_2 = config[DATA_SET]['epochs_2']\n",
    "    K = config[DATA_SET]['k']\n",
    "    dcn_obj = DCN(\n",
    "        DEVICE,\n",
    "        data_dim,\n",
    "        layer_dims,  # Provide the half (encoder only)\n",
    "        op_activation='sigmoid',\n",
    "        layer_activation='sigmoid',\n",
    "        dropout=0.1,\n",
    "        LR=0.05,\n",
    "        num_epochs_1=epochs_1,\n",
    "        num_epochs_2=epochs_2,\n",
    "        min_epochs=5,\n",
    "        batch_size=512,\n",
    "        k=K,\n",
    "        stop_threshold=0.05,\n",
    "        checkpoint_dir=DATA_SET,\n",
    "        Lambda=0.1\n",
    "    )\n",
    "    dcn_obj.train_model(train_X)\n",
    "    print(dcn_obj.centroids)\n",
    "    return dcn_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(\n",
    "    dcn_obj,\n",
    "    data_dict,\n",
    "    num_anomaly_sets\n",
    "):\n",
    "    test_X = data_dict['test'].values\n",
    "    test_labels = [0 for _ in range(test_X.shape[0])]\n",
    "    test_scores = dcn_obj.score_samples(test_X)\n",
    "    auc_list = []\n",
    "\n",
    "    for idx in range(num_anomaly_sets):\n",
    "        key = 'anom_' + str(idx+1)\n",
    "        anom_X = data_dict[key].values\n",
    "        anom_labels = [1 for _ in range(anom_X.shape[0])]\n",
    "        anom_scores = dcn_obj.score_samples(anom_X)\n",
    "\n",
    "        combined_scores = np.concatenate([anom_scores, test_scores], axis=0)\n",
    "        combined_labels = np.concatenate([anom_labels, test_labels], axis=0)\n",
    "\n",
    "        res_data = []\n",
    "        for i, j in zip(combined_scores, combined_labels):\n",
    "            res_data.append((i, j))\n",
    "        res_df = pd.DataFrame(res_data, columns=['score', 'label'])\n",
    "\n",
    "        #  Normalize values\n",
    "        def _normalize_(val, _min, _max):\n",
    "            return (val - _min) / (_max - _min)\n",
    "\n",
    "\n",
    "        _max = max(combined_scores)\n",
    "        _min = min(combined_scores)\n",
    "\n",
    "        res_df['score'] = res_df['score'].parallel_apply(\n",
    "            _normalize_,\n",
    "            args=(_min, _max,)\n",
    "        )\n",
    "\n",
    "        res_df = res_df.sort_values(by=['score'], ascending=False)\n",
    "        _max = max(res_df['score'])\n",
    "        _min = min(res_df['score'])\n",
    "        step = (_max - _min) / 100\n",
    "\n",
    "        # Vary the threshold\n",
    "        thresh = _max - step\n",
    "        num_anomalies = anom_X.shape[0]\n",
    "        P = []\n",
    "        R = [0]\n",
    "\n",
    "        while thresh >= _min:\n",
    "            sel = res_df.loc[res_df['score'] >= thresh]\n",
    "            if len(sel) == 0:\n",
    "                thresh -= step\n",
    "                continue\n",
    "            correct = sel.loc[sel['label'] == 1]\n",
    "            prec = len(correct) / len(sel)\n",
    "            rec = len(correct) / num_anomalies\n",
    "            P.append(prec)\n",
    "            R.append(rec)\n",
    "            if rec >= 1.0 :\n",
    "                break\n",
    "            thresh -= step\n",
    "            thresh = round(thresh,3)\n",
    "        P = [P[0]] + P\n",
    "        from sklearn.metrics import auc\n",
    "\n",
    "        pr_auc = auc(R, P)\n",
    "        auc_list.append(pr_auc)\n",
    "\n",
    "        print(\"AUC : {:0.4f} \".format(pr_auc))\n",
    "        try:\n",
    "            plt.figure()\n",
    "            plt.title('PR Curve' + str(pr_auc))\n",
    "            plt.plot(R, P)\n",
    "            plt.show()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    _mean = np.mean(auc_list)\n",
    "    _std = np.std(auc_list)\n",
    "    print(' Mean AUC ', np.mean(auc_list))\n",
    "    print(' AUC std', np.std(auc_list))\n",
    "    return _mean, _std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SET = 'kddcup'\n",
    "config_file = 'config.yaml'\n",
    "\n",
    "with open(config_file, 'r') as fh:\n",
    "    config = yaml.safe_load(fh)\n",
    "\n",
    "num_anomaly_sets = config[DATA_SET]['num_anomaly_sets']\n",
    "anomaly_ratio = config[DATA_SET]['anomaly_ratio']\n",
    "results = []\n",
    "\n",
    "\n",
    "data_dict, _ = data_fetcher.get_data(\n",
    "    DATA_SET,\n",
    "    one_hot=True,\n",
    "    num_anom_sets=num_anomaly_sets,\n",
    "    anomaly_ratio=anomaly_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device  >>  cuda\n",
      "=========================== \n",
      "DEVICE  cuda:2\n",
      "Adding layer index  0\n",
      "Adding layer index  1\n",
      "Adding layer index  2\n",
      ">>> module_LPT_AE(\n",
      "  (module_encoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=116, out_features=60, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=60, out_features=30, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=30, out_features=10, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (module_decoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=30, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=30, out_features=60, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=60, out_features=116, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Optimizer  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.05\n",
      "    weight_decay: 0\n",
      ")\n",
      "In init_centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9373778  0.44621    0.2782578  0.5380747  0.69155264 0.9296098\n",
      "  0.3468397  0.8608995  0.55631244 0.79708153]\n",
      " [0.07267552 0.28962365 0.09119094 0.12342767 0.19994697 0.03145273\n",
      "  0.19477253 0.1673521  0.1768133  0.01661569]\n",
      " [0.9440786  0.4556857  0.7141859  0.3519786  0.35156384 0.6950478\n",
      "  0.61491746 0.81135374 0.48943862 0.858854  ]\n",
      " [0.5023389  0.6845683  0.5788734  0.9370956  0.41087258 0.6930647\n",
      "  0.65126413 0.63337976 0.36294878 0.16414127]\n",
      " [0.1910169  0.6197666  0.30769652 0.1681009  0.8260582  0.44970447\n",
      "  0.3143441  0.51196086 0.81565017 0.04843181]]\n",
      "Exiting init_centroids\n",
      "<------------->\n",
      "Epoch :: 1\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(148.7398, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 14.899020\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(76.8498, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(32.3697, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(10.7460, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(5.9293, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(3.0998, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(2.1440, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(1.9392, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(1.6102, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(1.3272, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.9084, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(1.1937, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(1.2004, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.8898, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.9557, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6585, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6402, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3577, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5905, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4477, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2767, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1698, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2826, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2472, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2483, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3038, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1332, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2752, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1335, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2388, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0806, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1040, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1621, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1043, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1356, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1523, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0951, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1032, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1353, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0970, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1583, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1517, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1539, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1288, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1461, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1720, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2649, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1824, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2280, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1393, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2583, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1860, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1886, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2158, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1768, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2875, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2067, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2166, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1872, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1947, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1957, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2587, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2105, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2452, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2405, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2062, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2169, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2801, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2309, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1545, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3405, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1932, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1991, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1815, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2395, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2733, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2388, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3888, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2900, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2270, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2307, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2444, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2287, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2104, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2304, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2259, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3097, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2430, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2155, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1828, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2648, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2216, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2907, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2944, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2066, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2036, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2095, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1570, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2996, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2685, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2938, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 1.136568\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2952, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2858, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2286, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1501, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2683, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2089, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2502, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2869, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2747, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2937, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2707, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2125, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1908, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2155, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2050, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2462, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3318, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2767, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2922, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3197, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2783, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3520, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3180, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3083, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3685, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3264, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2987, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3388, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2355, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2271, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2663, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:06<02:08,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2476, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Epoch :: 2\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2753, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.759899\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3408, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3276, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2605, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2954, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2937, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2771, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2490, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2212, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2732, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2282, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2276, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2200, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2629, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2226, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2759, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2722, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2564, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2513, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2728, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3286, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3067, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3162, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3000, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2855, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2901, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2606, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2836, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2764, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2508, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2850, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2335, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2430, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2854, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3372, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2659, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2974, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2667, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3014, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3962, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2949, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3774, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3332, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3456, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3465, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3193, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3263, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3148, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2964, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3375, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3582, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3356, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3120, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3027, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2692, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3539, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3002, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2986, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3145, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3401, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2537, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2699, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3088, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2230, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2224, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2826, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2166, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2371, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2597, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3911, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2472, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3144, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2609, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2920, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2602, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2898, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3141, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2596, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2847, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3285, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2910, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3233, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3226, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2992, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3318, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3313, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3590, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3591, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4246, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3388, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3297, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3873, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3194, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2752, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2864, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3007, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2543, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2963, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3299, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3022, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2921, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.878704\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2991, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3215, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3524, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3748, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4048, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3330, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3322, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3398, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3386, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3610, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3704, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2848, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2840, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2443, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2842, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2640, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2749, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2441, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3024, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2813, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2951, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2770, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3145, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2760, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3347, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2985, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3248, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2802, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2829, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2380, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2505, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:23<02:56,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2934, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Epoch :: 3\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3132, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.713950\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2911, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2256, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3245, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3418, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3074, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3072, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3321, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3529, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3342, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3259, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3851, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5082, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3933, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3120, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2940, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2840, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2514, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3371, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3147, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3209, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3034, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3214, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2750, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3393, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3151, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4236, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2977, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3256, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2898, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3673, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3224, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3100, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2909, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2342, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2446, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2161, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2552, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2587, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2441, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2318, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2872, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2487, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2955, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3123, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2746, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2815, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3229, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3477, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3189, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3162, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3339, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3364, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3459, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3058, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3277, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3498, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3781, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3375, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3062, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3204, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2767, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3190, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3060, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2669, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3193, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3132, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3286, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3422, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2871, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3214, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3745, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3904, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4352, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3849, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3271, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3400, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2954, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3130, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3144, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2955, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3015, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3072, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3543, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3709, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3828, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3387, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3854, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3967, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3228, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3253, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3584, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3824, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3696, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3716, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4424, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4673, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5174, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4755, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4609, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4467, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.739574\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4927, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4679, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4727, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5365, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4937, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5115, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5540, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5257, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5728, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5415, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5492, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5149, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5226, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4740, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4907, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4629, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4589, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4456, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4190, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4278, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4271, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4465, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3980, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4276, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4683, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5381, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4926, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6098, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5862, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5877, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5949, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6108, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:49<04:08, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 4\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5668, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.714263\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5980, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6408, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6578, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5735, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5282, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5500, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5732, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5192, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5061, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5340, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5065, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4779, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4516, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5116, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4626, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4641, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5146, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4333, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4379, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4666, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4581, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4291, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4631, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4997, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4480, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4923, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4942, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4909, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5029, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5053, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4579, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4276, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4320, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4185, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3864, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3857, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3681, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3402, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3617, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3420, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3663, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3543, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3431, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3111, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3162, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3235, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2953, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2765, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3102, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3387, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3128, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3056, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3173, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3366, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3349, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3306, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3154, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2999, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3192, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2945, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2967, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2863, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2692, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3504, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2725, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2953, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2727, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2914, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2795, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2843, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2661, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2887, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2787, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2514, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2769, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2438, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2723, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2771, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3017, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2894, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3094, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3275, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3664, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3179, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2806, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2928, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2899, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2705, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2981, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3028, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3009, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3325, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3027, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3046, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3568, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3082, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3418, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4154, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3607, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3476, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.807982\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3199, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3418, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3632, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3788, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4117, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3743, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3844, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3952, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4099, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4153, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3463, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3591, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3820, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3245, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3314, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3087, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3477, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3326, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2933, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2797, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2870, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2613, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2742, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2582, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2728, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2655, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2541, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2688, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2300, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2384, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2658, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2325, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:24<05:32, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 5\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2368, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.637149\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2640, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2154, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2486, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2585, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2322, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2256, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2337, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2150, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2083, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2279, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2165, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2435, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2124, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2369, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2141, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2233, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2377, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2197, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2143, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2265, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2335, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2136, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2016, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2237, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2282, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2158, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2352, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2430, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2406, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2212, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2595, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2219, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2334, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2115, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2236, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2037, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2386, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2250, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2073, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1778, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2010, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2009, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2199, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2176, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2232, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2428, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2105, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1992, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1922, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1980, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1848, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1977, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1628, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1763, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1515, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1806, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1799, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1857, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1657, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1893, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2159, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2290, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2157, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2515, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3219, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5255, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6165, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.7755, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.7302, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.7327, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6687, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5153, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5331, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3804, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5080, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6292, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4701, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4881, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3809, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4196, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4890, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4519, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3725, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3894, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4371, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3674, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4529, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2650, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2401, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2490, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1979, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1999, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1610, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1751, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1644, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1595, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2429, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1447, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1438, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1207, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 1.234029\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1083, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1311, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1112, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1151, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0836, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0832, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0942, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1148, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1190, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1244, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0970, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0949, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0932, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0985, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0932, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0914, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0989, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0903, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0916, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1020, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0852, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0984, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1422, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1071, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0933, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1304, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1259, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1106, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1474, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1383, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1398, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1403, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:11<07:08, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 6\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1755, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 1.147980\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1606, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2086, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1855, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1624, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1975, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2056, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2489, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2364, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2666, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2156, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2519, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2484, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2312, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2146, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2082, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1794, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1947, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2534, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2319, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2309, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2439, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2347, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2221, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2029, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2739, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2245, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2016, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2109, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1600, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1740, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1661, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1664, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2348, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1443, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1316, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1271, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1290, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1364, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1183, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1330, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1197, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0894, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1127, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1182, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0970, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1216, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1150, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0954, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1085, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2441, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1152, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1313, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1158, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1339, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0958, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1081, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0976, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0878, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0775, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1106, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0969, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0993, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0711, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1045, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1120, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1019, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0833, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2446, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1018, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0855, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1063, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0930, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0955, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1051, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1052, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1300, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1732, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0998, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1029, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0982, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1163, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1014, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1062, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1023, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0864, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0825, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0855, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0842, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0799, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0945, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0962, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1076, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0760, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0707, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0791, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0799, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0864, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0851, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1102, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0994, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 1.101116\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0919, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0794, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0746, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0715, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0900, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0852, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0752, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0764, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0774, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0835, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0753, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0821, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0702, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0609, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0841, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0760, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0633, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0669, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0861, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0936, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0757, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0814, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0769, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0846, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0858, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1020, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0755, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1028, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0990, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0870, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1055, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1011, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:07<08:37, 36.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 7\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1077, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.990033\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0923, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1128, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0971, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1105, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1270, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1289, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1383, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1356, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1514, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1629, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1308, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1043, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1564, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1979, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1096, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0880, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0700, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0976, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1052, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1027, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1229, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1073, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1192, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1433, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1357, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1052, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1759, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1293, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1261, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1043, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1358, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1279, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1361, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1049, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1340, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1127, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1167, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1016, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1376, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0893, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1235, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1165, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1656, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2188, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2680, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2216, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1505, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1286, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1313, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2685, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2140, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2466, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4213, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3615, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2476, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2589, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2034, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2238, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2515, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2833, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2958, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3426, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3796, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4261, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4034, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3501, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2980, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2700, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2594, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2061, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2477, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2376, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2440, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2395, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1952, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1708, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1748, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1680, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1854, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1889, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2062, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2003, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1752, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1950, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1805, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1691, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1661, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1732, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1594, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1520, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1364, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1396, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1370, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1390, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1808, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1627, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1635, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1736, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2071, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2134, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.918001\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2430, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2342, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2181, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2550, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2393, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2511, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2463, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2994, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3372, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3827, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3741, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3988, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5172, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5868, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.6409, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5761, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5110, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4826, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.5569, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4806, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.4361, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3747, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2853, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2857, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.3031, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2920, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2443, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2341, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2268, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2425, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2090, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2019, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:13<09:51, 45.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 8\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1844, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.862464\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1750, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1741, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1475, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1591, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1416, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1403, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1459, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1417, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1283, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1383, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1258, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1314, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1317, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1416, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1279, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1237, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1230, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1250, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1247, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1232, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1331, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1243, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1528, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1332, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1299, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1408, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1309, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1167, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1348, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1246, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1264, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1189, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1297, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1268, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1191, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1208, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1250, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1288, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1177, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1161, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1150, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1118, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1167, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1174, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1129, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1175, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1133, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1130, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1177, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1051, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1048, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1052, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1035, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1078, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1004, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1047, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1053, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1075, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1023, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1040, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1270, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1054, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0966, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0901, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1019, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1129, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1013, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0946, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0944, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1009, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1171, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0957, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0882, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1293, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0968, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0970, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1004, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0995, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0922, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1051, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0944, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0920, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0982, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0901, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1047, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0968, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0991, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1709, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0895, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0909, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1029, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0983, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1070, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0983, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0908, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1065, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0906, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0850, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0834, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1400, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.810147\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0913, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0791, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0854, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0901, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0847, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0868, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0871, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0906, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0968, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0840, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0897, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0870, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0892, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0797, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0798, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0980, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0882, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0957, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0865, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0917, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0863, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0986, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0929, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0844, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0985, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1025, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1002, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1051, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1117, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1248, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1221, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1269, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [05:28<10:53, 54.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 9\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1281, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.922071\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1358, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1481, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1474, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1691, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2085, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1689, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1755, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1983, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2071, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2057, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1728, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1985, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2101, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1728, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1713, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1628, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1727, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1662, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1467, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1466, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1589, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1648, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1757, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1788, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1896, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1811, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1952, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2254, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2340, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2392, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2215, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2073, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2413, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2240, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2131, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2126, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2025, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1953, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1798, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1563, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1791, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1721, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.2033, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1802, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1462, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1635, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1461, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1460, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1466, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1372, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1241, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1286, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1332, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1257, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1179, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1171, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1130, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1279, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1215, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1274, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1192, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1148, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1038, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1125, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0935, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0812, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0972, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0897, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0842, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0909, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0818, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0913, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0917, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0906, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0803, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0852, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0947, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0851, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0893, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0789, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0967, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0825, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0867, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0824, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0857, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0872, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0838, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0838, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0904, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0869, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0822, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1006, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0867, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0841, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0970, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0908, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0841, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0891, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0801, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0924, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 1.047823\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0889, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0866, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0778, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0947, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0901, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0785, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0836, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0821, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0754, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0871, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0811, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0768, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0845, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0838, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0853, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0723, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0765, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0922, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0830, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0853, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0767, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0954, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0915, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0805, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0789, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0744, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0839, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0819, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0837, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0824, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0848, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([510, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0853, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:50<11:29, 62.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters updated\n",
      "Epoch :: 10\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0793, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "Loss 0.740057\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0795, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0902, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0721, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0934, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0896, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0912, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0862, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0828, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0755, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0840, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0860, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0794, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0881, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0945, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0809, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0727, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0774, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0844, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0829, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0795, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0767, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0953, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0889, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0951, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0806, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0792, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0875, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0782, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0896, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1025, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1268, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1448, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1259, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1371, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1454, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1116, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1092, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1169, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1088, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1121, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1011, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1002, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1069, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0995, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1057, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1195, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0930, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0987, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1258, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1273, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1080, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0916, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1048, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0958, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0954, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1075, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0963, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1107, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1069, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1147, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1187, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.0964, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1337, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1347, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1304, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1420, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1372, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1285, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1313, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1185, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1244, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1234, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1140, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1550, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1316, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1267, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1409, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1320, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1457, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1420, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1511, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1581, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1596, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1548, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1660, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1723, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1661, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1493, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1451, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1450, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1585, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1372, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1497, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1553, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1629, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1599, device='cuda:2', grad_fn=<SumBackward1>)\n",
      "Network parameters updated\n",
      "torch.Size([512, 116])\n",
      "Step 2\n",
      " Clustering loss  tensor(0.1522, device='cuda:2', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "dcn_obj = train_model(DATA_SET, data_dict, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aupr, std = test_eval(dcn_obj, data_dict, num_anomaly_sets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 76)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = train_X.shape[1]\n",
    "layer_dims = [64,32,16,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn_obj = DCN(\n",
    "        DEVICE,\n",
    "        data_dim,\n",
    "        layer_dims,  # Provide the half (encoder only)\n",
    "        op_activation='sigmoid',\n",
    "        layer_activation='sigmoid',\n",
    "        dropout=0.005,\n",
    "        LR=0.05,\n",
    "        num_epochs_1=25,\n",
    "        num_epochs_2=100,\n",
    "        min_epochs = 20,\n",
    "        batch_size=512,\n",
    "        k=5,\n",
    "        stop_threshold=0.05,\n",
    "        checkpoint_dir=DATA_SET,\n",
    "        Lambda = 0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer index  0\n",
      "Adding layer index  1\n",
      "Adding layer index  2\n",
      "Adding layer index  3\n",
      "In init_centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dcn_obj.train_model(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0]\n",
    "])\n",
    "\n",
    "\n",
    "idx = FT(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16499129, 0.23580414, 0.33488992, 0.06355508],\n",
       "       [0.11445248, 0.29347017, 0.9099661 , 0.87875825],\n",
       "       [0.7070779 , 0.56847817, 0.40286165, 0.85527784],\n",
       "       [0.72176766, 0.14774324, 0.3654089 , 0.2072641 ],\n",
       "       [0.24768673, 0.9049612 , 0.614901  , 0.29580304]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = FT(dcn_obj.centroids)\n",
    "dcn_obj.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.1145, 0.2935, 0.9100, 0.8788],\n",
       "        [0.7218, 0.1477, 0.3654, 0.2073],\n",
       "        [0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.7218, 0.1477, 0.3654, 0.2073],\n",
       "        [0.2477, 0.9050, 0.6149, 0.2958],\n",
       "        [0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.2477, 0.9050, 0.6149, 0.2958],\n",
       "        [0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.7218, 0.1477, 0.3654, 0.2073],\n",
       "        [0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.1650, 0.2358, 0.3349, 0.0636],\n",
       "        [0.2477, 0.9050, 0.6149, 0.2958],\n",
       "        [0.1145, 0.2935, 0.9100, 0.8788],\n",
       "        [0.7071, 0.5685, 0.4029, 0.8553]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[torch.max(idx,dim=1,keepdim=False)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = p2 - dec_obj.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3357, 0.4071, 0.4718, 0.3362, 0.5547],\n",
       "        [0.3351, 0.4063, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3351, 0.4063, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3351, 0.4063, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3361, 0.4076, 0.4723, 0.3366, 0.5553],\n",
       "        [0.3351, 0.4062, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3351, 0.4063, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3351, 0.4063, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3351, 0.4063, 0.4711, 0.3355, 0.5538],\n",
       "        [0.3370, 0.4090, 0.4738, 0.3378, 0.5571]], device='cuda:0',\n",
       "       grad_fn=<ReciprocalBackward>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3 = p3**2\n",
    "p4 = torch.reciprocal(1 + torch.sum(p3,dim=-1))\n",
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1055],\n",
       "        [2.1018],\n",
       "        [2.1018],\n",
       "        [2.1018],\n",
       "        [2.1078],\n",
       "        [2.1017],\n",
       "        [2.1018],\n",
       "        [2.1017],\n",
       "        [2.1018],\n",
       "        [2.1147]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5 = torch.sum(p4,dim=1,keepdim=True)\n",
    "p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595, 0.1933, 0.2241, 0.1597, 0.2634],\n",
       "        [0.1595, 0.1933, 0.2241, 0.1596, 0.2635],\n",
       "        [0.1595, 0.1933, 0.2241, 0.1596, 0.2635],\n",
       "        [0.1595, 0.1933, 0.2241, 0.1596, 0.2635],\n",
       "        [0.1594, 0.1934, 0.2241, 0.1597, 0.2634],\n",
       "        [0.1594, 0.1933, 0.2242, 0.1596, 0.2635],\n",
       "        [0.1595, 0.1933, 0.2241, 0.1596, 0.2635],\n",
       "        [0.1595, 0.1933, 0.2241, 0.1596, 0.2635],\n",
       "        [0.1595, 0.1933, 0.2241, 0.1596, 0.2635],\n",
       "        [0.1594, 0.1934, 0.2241, 0.1597, 0.2635]], device='cuda:0',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4/p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8460, 0.3456, 0.9193, 0.5336],\n",
      "         [0.4398, 0.5151, 0.8792, 0.4597],\n",
      "         [0.4044, 0.4447, 0.5632, 0.6559],\n",
      "         [0.8425, 0.5652, 0.7528, 0.6015],\n",
      "         [0.3383, 0.4091, 0.4403, 0.5636]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4477, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5971],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5592]],\n",
      "\n",
      "        [[0.8511, 0.3579, 0.9212, 0.5314],\n",
      "         [0.4449, 0.5274, 0.8810, 0.4575],\n",
      "         [0.4095, 0.4570, 0.5650, 0.6537],\n",
      "         [0.8477, 0.5775, 0.7547, 0.5993],\n",
      "         [0.3435, 0.4215, 0.4421, 0.5614]],\n",
      "\n",
      "        [[0.8530, 0.3570, 0.9214, 0.5298],\n",
      "         [0.4468, 0.5265, 0.8813, 0.4559],\n",
      "         [0.4113, 0.4561, 0.5652, 0.6520],\n",
      "         [0.8495, 0.5766, 0.7549, 0.5977],\n",
      "         [0.3453, 0.4206, 0.4423, 0.5598]],\n",
      "\n",
      "        [[0.8473, 0.3494, 0.9199, 0.5334],\n",
      "         [0.4411, 0.5188, 0.8798, 0.4595],\n",
      "         [0.4057, 0.4485, 0.5638, 0.6557],\n",
      "         [0.8438, 0.5689, 0.7534, 0.6013],\n",
      "         [0.3396, 0.4129, 0.4409, 0.5634]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5308],\n",
      "         [0.4457, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4563, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4018, 2.2013, 2.0529, 2.3992, 1.8907],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4084, 2.2090, 2.0598, 2.4074, 1.8979],\n",
      "        [2.4088, 2.2088, 2.0592, 2.4075, 1.8973],\n",
      "        [2.4038, 2.2037, 2.0552, 2.4018, 1.8931],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0595, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4073, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4163, 0.4543, 0.4871, 0.4168, 0.5289],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4151, 0.4527, 0.4856, 0.4154, 0.5271],\n",
      "        [0.4160, 0.4538, 0.4866, 0.4164, 0.5282],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8514, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4452, 0.5270, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5771, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4211, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4209, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8468, 0.3484, 0.9197, 0.5334],\n",
      "         [0.4406, 0.5178, 0.8796, 0.4595],\n",
      "         [0.4052, 0.4474, 0.5635, 0.6557],\n",
      "         [0.8433, 0.5679, 0.7532, 0.6014],\n",
      "         [0.3391, 0.4119, 0.4406, 0.5635]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4032, 2.2030, 2.0545, 2.4009, 1.8924],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4161, 0.4539, 0.4867, 0.4165, 0.5284],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8514, 0.3577, 0.9213, 0.5311],\n",
      "         [0.4452, 0.5272, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4568, 0.5651, 0.6534],\n",
      "         [0.8479, 0.5773, 0.7548, 0.5991],\n",
      "         [0.3437, 0.4212, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8510, 0.3580, 0.9212, 0.5314],\n",
      "         [0.4448, 0.5275, 0.8810, 0.4575],\n",
      "         [0.4094, 0.4571, 0.5650, 0.6537],\n",
      "         [0.8476, 0.5776, 0.7546, 0.5993],\n",
      "         [0.3434, 0.4216, 0.4421, 0.5615]],\n",
      "\n",
      "        [[0.8537, 0.3559, 0.9216, 0.5294],\n",
      "         [0.4475, 0.5253, 0.8815, 0.4555],\n",
      "         [0.4120, 0.4550, 0.5654, 0.6517],\n",
      "         [0.8502, 0.5754, 0.7551, 0.5973],\n",
      "         [0.3460, 0.4194, 0.4425, 0.5594]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9213, 0.5311],\n",
      "         [0.4453, 0.5270, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8481, 0.5771, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4211, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4083, 2.2090, 2.0598, 2.4074, 1.8979],\n",
      "        [2.4089, 2.2086, 2.0589, 2.4075, 1.8969],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8978],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5308],\n",
      "         [0.4457, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8484, 0.5768, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8482, 0.3513, 0.9203, 0.5333],\n",
      "         [0.4420, 0.5208, 0.8801, 0.4594],\n",
      "         [0.4066, 0.4504, 0.5641, 0.6555],\n",
      "         [0.8447, 0.5709, 0.7538, 0.6012],\n",
      "         [0.3405, 0.4148, 0.4412, 0.5633]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4050, 2.2051, 2.0565, 2.4032, 1.8944],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4158, 0.4535, 0.4863, 0.4161, 0.5279],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4452, 0.5270, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5771, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4100, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3439, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5989],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8473, 0.3493, 0.9199, 0.5334],\n",
      "         [0.4411, 0.5188, 0.8798, 0.4595],\n",
      "         [0.4056, 0.4484, 0.5638, 0.6557],\n",
      "         [0.8438, 0.5689, 0.7534, 0.6013],\n",
      "         [0.3396, 0.4129, 0.4408, 0.5634]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4038, 2.2037, 2.0552, 2.4017, 1.8931],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4160, 0.4538, 0.4866, 0.4164, 0.5282],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8539, 0.3556, 0.9216, 0.5293],\n",
      "         [0.4477, 0.5251, 0.8815, 0.4554],\n",
      "         [0.4122, 0.4547, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5752, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4101, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4100, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8482, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3440, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4457, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8533, 0.3566, 0.9215, 0.5294],\n",
      "         [0.4471, 0.5261, 0.8813, 0.4555],\n",
      "         [0.4117, 0.4557, 0.5653, 0.6517],\n",
      "         [0.8499, 0.5762, 0.7550, 0.5973],\n",
      "         [0.3456, 0.4202, 0.4424, 0.5594]],\n",
      "\n",
      "        [[0.8478, 0.3505, 0.9201, 0.5333],\n",
      "         [0.4416, 0.5200, 0.8800, 0.4594],\n",
      "         [0.4062, 0.4496, 0.5640, 0.6556],\n",
      "         [0.8444, 0.5701, 0.7536, 0.6013],\n",
      "         [0.3402, 0.4140, 0.4411, 0.5634]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4088, 2.2087, 2.0590, 2.4075, 1.8970],\n",
      "        [2.4046, 2.2045, 2.0560, 2.4026, 1.8939],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5271],\n",
      "        [0.4159, 0.4536, 0.4864, 0.4162, 0.5280],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8496, 0.3540, 0.9208, 0.5327],\n",
      "         [0.4434, 0.5234, 0.8806, 0.4588],\n",
      "         [0.4080, 0.4530, 0.5646, 0.6550],\n",
      "         [0.8461, 0.5735, 0.7542, 0.6006],\n",
      "         [0.3419, 0.4175, 0.4417, 0.5627]],\n",
      "\n",
      "        [[0.8538, 0.3557, 0.9216, 0.5294],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4555],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6517],\n",
      "         [0.8503, 0.5753, 0.7551, 0.5973],\n",
      "         [0.3461, 0.4192, 0.4426, 0.5594]],\n",
      "\n",
      "        [[0.8456, 0.3463, 0.9193, 0.5333],\n",
      "         [0.4394, 0.5158, 0.8791, 0.4594],\n",
      "         [0.4039, 0.4454, 0.5631, 0.6556],\n",
      "         [0.8421, 0.5659, 0.7527, 0.6012],\n",
      "         [0.3379, 0.4099, 0.4402, 0.5633]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4209, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3577, 0.9213, 0.5312],\n",
      "         [0.4453, 0.5272, 0.8811, 0.4573],\n",
      "         [0.4099, 0.4568, 0.5651, 0.6535],\n",
      "         [0.8480, 0.5773, 0.7547, 0.5991],\n",
      "         [0.3438, 0.4212, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8360, 0.3526, 0.9165, 0.5308],\n",
      "         [0.4298, 0.5221, 0.8764, 0.4569],\n",
      "         [0.3943, 0.4517, 0.5604, 0.6531],\n",
      "         [0.8325, 0.5722, 0.7500, 0.5987],\n",
      "         [0.3283, 0.4161, 0.4375, 0.5608]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4067, 2.2069, 2.0581, 2.4052, 1.8961],\n",
      "        [2.4090, 2.2086, 2.0588, 2.4075, 1.8969],\n",
      "        [2.4016, 2.2013, 2.0528, 2.3991, 1.8907],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4075, 1.8978],\n",
      "        [2.3946, 2.1975, 2.0489, 2.3934, 1.8871]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4155, 0.4531, 0.4859, 0.4158, 0.5274],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4164, 0.4543, 0.4871, 0.4168, 0.5289],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4176, 0.4551, 0.4881, 0.4178, 0.5299]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1971, 0.2114, 0.1810, 0.2296]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8492, 0.3532, 0.9206, 0.5329],\n",
      "         [0.4430, 0.5226, 0.8805, 0.4590],\n",
      "         [0.4075, 0.4522, 0.5644, 0.6552],\n",
      "         [0.8457, 0.5727, 0.7541, 0.6008],\n",
      "         [0.3415, 0.4167, 0.4415, 0.5629]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4477, 0.5251, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5752, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3576, 0.9213, 0.5312],\n",
      "         [0.4453, 0.5271, 0.8811, 0.4573],\n",
      "         [0.4098, 0.4567, 0.5651, 0.6534],\n",
      "         [0.8480, 0.5772, 0.7548, 0.5991],\n",
      "         [0.3438, 0.4212, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8462, 0.3471, 0.9195, 0.5334],\n",
      "         [0.4400, 0.5166, 0.8794, 0.4595],\n",
      "         [0.4046, 0.4462, 0.5633, 0.6557],\n",
      "         [0.8428, 0.5667, 0.7530, 0.6013],\n",
      "         [0.3386, 0.4107, 0.4404, 0.5634]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4062, 2.2064, 2.0576, 2.4046, 1.8956],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4024, 2.2021, 2.0536, 2.4000, 1.8915]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4156, 0.4532, 0.4860, 0.4159, 0.5275],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4163, 0.4541, 0.4869, 0.4167, 0.5287]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8469, 0.3485, 0.9198, 0.5334],\n",
      "         [0.4407, 0.5179, 0.8796, 0.4595],\n",
      "         [0.4052, 0.4476, 0.5636, 0.6557],\n",
      "         [0.8434, 0.5680, 0.7532, 0.6013],\n",
      "         [0.3392, 0.4120, 0.4407, 0.5634]],\n",
      "\n",
      "        [[0.8520, 0.3572, 0.9214, 0.5308],\n",
      "         [0.4458, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4104, 0.4563, 0.5652, 0.6531],\n",
      "         [0.8486, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8533, 0.3565, 0.9215, 0.5294],\n",
      "         [0.4471, 0.5260, 0.8814, 0.4555],\n",
      "         [0.4117, 0.4556, 0.5653, 0.6517],\n",
      "         [0.8499, 0.5761, 0.7550, 0.5974],\n",
      "         [0.3457, 0.4201, 0.4424, 0.5595]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3575, 0.9213, 0.5311],\n",
      "         [0.4454, 0.5270, 0.8812, 0.4572],\n",
      "         [0.4100, 0.4566, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5771, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8520, 0.3572, 0.9214, 0.5308],\n",
      "         [0.4458, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4104, 0.4563, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5608]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4033, 2.2031, 2.0546, 2.4011, 1.8924],\n",
      "        [2.4087, 2.2089, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4088, 2.2087, 2.0590, 2.4075, 1.8970],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0596, 2.4074, 1.8978],\n",
      "        [2.4086, 2.2089, 2.0595, 2.4075, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4161, 0.4539, 0.4867, 0.4165, 0.5284],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5271],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8467, 0.3413, 0.9194, 0.5346],\n",
      "         [0.4405, 0.5107, 0.8793, 0.4607],\n",
      "         [0.4050, 0.4403, 0.5632, 0.6569],\n",
      "         [0.8432, 0.5608, 0.7529, 0.6026],\n",
      "         [0.3390, 0.4048, 0.4403, 0.5647]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4016, 2.2001, 2.0520, 2.3984, 1.8897],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4164, 0.4545, 0.4873, 0.4170, 0.5292],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1807, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3556, 0.9216, 0.5293],\n",
      "         [0.4476, 0.5251, 0.8815, 0.4554],\n",
      "         [0.4122, 0.4547, 0.5655, 0.6516],\n",
      "         [0.8504, 0.5752, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5971],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8502, 0.3588, 0.9209, 0.5318],\n",
      "         [0.4440, 0.5283, 0.8807, 0.4579],\n",
      "         [0.4086, 0.4579, 0.5647, 0.6541],\n",
      "         [0.8467, 0.5784, 0.7544, 0.5997],\n",
      "         [0.3425, 0.4224, 0.4418, 0.5618]],\n",
      "\n",
      "        [[0.8514, 0.3578, 0.9212, 0.5312],\n",
      "         [0.4452, 0.5273, 0.8811, 0.4573],\n",
      "         [0.4098, 0.4569, 0.5650, 0.6535],\n",
      "         [0.8479, 0.5774, 0.7547, 0.5992],\n",
      "         [0.3437, 0.4213, 0.4421, 0.5613]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8478, 0.3504, 0.9201, 0.5333],\n",
      "         [0.4416, 0.5199, 0.8800, 0.4594],\n",
      "         [0.4062, 0.4495, 0.5639, 0.6556],\n",
      "         [0.8443, 0.5700, 0.7536, 0.6013],\n",
      "         [0.3401, 0.4140, 0.4410, 0.5634]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4080, 2.2090, 2.0599, 2.4072, 1.8981],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8979],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4045, 2.2045, 2.0559, 2.4026, 1.8938],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4153, 0.4527, 0.4855, 0.4154, 0.5268],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4159, 0.4536, 0.4864, 0.4162, 0.5280],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4477, 0.5251, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5752, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4100, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3439, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8536, 0.3559, 0.9216, 0.5295],\n",
      "         [0.4474, 0.5254, 0.8815, 0.4556],\n",
      "         [0.4120, 0.4550, 0.5654, 0.6518],\n",
      "         [0.8502, 0.5755, 0.7551, 0.5974],\n",
      "         [0.3460, 0.4194, 0.4425, 0.5595]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2086, 2.0589, 2.4075, 1.8969],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5270, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4566, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5771, 0.7548, 0.5989],\n",
      "         [0.3439, 0.4211, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8493, 0.3534, 0.9207, 0.5329],\n",
      "         [0.4431, 0.5229, 0.8805, 0.4590],\n",
      "         [0.4077, 0.4525, 0.5645, 0.6551],\n",
      "         [0.8458, 0.5730, 0.7541, 0.6008],\n",
      "         [0.3416, 0.4170, 0.4416, 0.5629]],\n",
      "\n",
      "        [[0.8499, 0.3590, 0.9208, 0.5319],\n",
      "         [0.4437, 0.5285, 0.8807, 0.4580],\n",
      "         [0.4083, 0.4581, 0.5646, 0.6542],\n",
      "         [0.8464, 0.5786, 0.7543, 0.5998],\n",
      "         [0.3422, 0.4226, 0.4417, 0.5619]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8532, 0.3567, 0.9215, 0.5295],\n",
      "         [0.4470, 0.5262, 0.8813, 0.4556],\n",
      "         [0.4116, 0.4558, 0.5653, 0.6517],\n",
      "         [0.8498, 0.5763, 0.7549, 0.5974],\n",
      "         [0.3456, 0.4203, 0.4424, 0.5595]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4064, 2.2065, 2.0578, 2.4048, 1.8958],\n",
      "        [2.4079, 2.2089, 2.0599, 2.4071, 1.8981],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4088, 2.2087, 2.0590, 2.4075, 1.8971],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4156, 0.4532, 0.4860, 0.4158, 0.5275],\n",
      "        [0.4153, 0.4527, 0.4855, 0.4154, 0.5268],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5271],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8506, 0.3585, 0.9210, 0.5316],\n",
      "         [0.4444, 0.5280, 0.8808, 0.4577],\n",
      "         [0.4090, 0.4576, 0.5648, 0.6539],\n",
      "         [0.8471, 0.5781, 0.7545, 0.5996],\n",
      "         [0.3429, 0.4220, 0.4419, 0.5617]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8511, 0.3580, 0.9212, 0.5314],\n",
      "         [0.4449, 0.5274, 0.8810, 0.4575],\n",
      "         [0.4095, 0.4570, 0.5650, 0.6537],\n",
      "         [0.8476, 0.5775, 0.7547, 0.5993],\n",
      "         [0.3434, 0.4215, 0.4421, 0.5614]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4082, 2.2090, 2.0598, 2.4073, 1.8980],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2090, 2.0598, 2.4074, 1.8979],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4153, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5308],\n",
      "         [0.4457, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4101, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5610]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8522, 0.3571, 0.9214, 0.5306],\n",
      "         [0.4460, 0.5266, 0.8813, 0.4567],\n",
      "         [0.4106, 0.4562, 0.5653, 0.6529],\n",
      "         [0.8487, 0.5767, 0.7549, 0.5986],\n",
      "         [0.3445, 0.4207, 0.4424, 0.5607]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4101, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8470, 0.3488, 0.9198, 0.5334],\n",
      "         [0.4408, 0.5183, 0.8797, 0.4595],\n",
      "         [0.4054, 0.4479, 0.5636, 0.6557],\n",
      "         [0.8435, 0.5684, 0.7533, 0.6013],\n",
      "         [0.3393, 0.4124, 0.4407, 0.5634]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8521, 0.3572, 0.9214, 0.5307],\n",
      "         [0.4459, 0.5267, 0.8813, 0.4568],\n",
      "         [0.4104, 0.4563, 0.5653, 0.6530],\n",
      "         [0.8486, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3444, 0.4207, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8517, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4455, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4100, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8482, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3440, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4087, 2.2089, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4035, 2.2033, 2.0548, 2.4013, 1.8927],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4087, 2.2089, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4856, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4161, 0.4539, 0.4867, 0.4164, 0.5283],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8517, 0.3574, 0.9213, 0.5308],\n",
      "         [0.4455, 0.5269, 0.8812, 0.4569],\n",
      "         [0.4100, 0.4565, 0.5651, 0.6531],\n",
      "         [0.8482, 0.5770, 0.7548, 0.5988],\n",
      "         [0.3440, 0.4210, 0.4422, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2088, 2.0595, 2.4073, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4856, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8538, 0.3557, 0.9216, 0.5293],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4554],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6516],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8493, 0.3535, 0.9207, 0.5328],\n",
      "         [0.4431, 0.5229, 0.8805, 0.4589],\n",
      "         [0.4077, 0.4525, 0.5645, 0.6551],\n",
      "         [0.8459, 0.5730, 0.7542, 0.6008],\n",
      "         [0.3417, 0.4170, 0.4416, 0.5629]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3439, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8539, 0.3555, 0.9216, 0.5293],\n",
      "         [0.4477, 0.5250, 0.8815, 0.4554],\n",
      "         [0.4123, 0.4546, 0.5655, 0.6516],\n",
      "         [0.8504, 0.5751, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4191, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4477, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5971],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5592]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8486, 0.3521, 0.9204, 0.5331],\n",
      "         [0.4424, 0.5216, 0.8803, 0.4592],\n",
      "         [0.4070, 0.4512, 0.5643, 0.6554],\n",
      "         [0.8452, 0.5717, 0.7539, 0.6011],\n",
      "         [0.3410, 0.4156, 0.4413, 0.5632]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4064, 2.2066, 2.0578, 2.4048, 1.8958],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4090, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4056, 2.2056, 2.0570, 2.4038, 1.8950],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4156, 0.4532, 0.4860, 0.4158, 0.5275],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4157, 0.4534, 0.4862, 0.4160, 0.5277],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9213, 0.5309],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4570],\n",
      "         [0.4100, 0.4565, 0.5651, 0.6532],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5989],\n",
      "         [0.3439, 0.4210, 0.4422, 0.5610]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3576, 0.9213, 0.5311],\n",
      "         [0.4453, 0.5271, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4567, 0.5651, 0.6534],\n",
      "         [0.8480, 0.5772, 0.7548, 0.5991],\n",
      "         [0.3438, 0.4211, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8538, 0.3554, 0.9216, 0.5297],\n",
      "         [0.4476, 0.5249, 0.8815, 0.4558],\n",
      "         [0.4122, 0.4545, 0.5655, 0.6520],\n",
      "         [0.8503, 0.5750, 0.7551, 0.5976],\n",
      "         [0.3461, 0.4190, 0.4426, 0.5597]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0595, 2.4073, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4090, 2.2086, 2.0589, 2.4075, 1.8969]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4856, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8514, 0.3576, 0.9213, 0.5312],\n",
      "         [0.4452, 0.5271, 0.8812, 0.4573],\n",
      "         [0.4098, 0.4567, 0.5651, 0.6534],\n",
      "         [0.8480, 0.5772, 0.7548, 0.5991],\n",
      "         [0.3438, 0.4212, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4457, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8537, 0.3558, 0.9216, 0.5294],\n",
      "         [0.4475, 0.5253, 0.8815, 0.4555],\n",
      "         [0.4121, 0.4549, 0.5654, 0.6516],\n",
      "         [0.8503, 0.5754, 0.7551, 0.5973],\n",
      "         [0.3461, 0.4193, 0.4425, 0.5594]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2086, 2.0588, 2.4075, 1.8969],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3556, 0.9216, 0.5293],\n",
      "         [0.4477, 0.5250, 0.8815, 0.4554],\n",
      "         [0.4123, 0.4547, 0.5655, 0.6516],\n",
      "         [0.8504, 0.5751, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4191, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8485, 0.3518, 0.9204, 0.5332],\n",
      "         [0.4422, 0.5212, 0.8802, 0.4593],\n",
      "         [0.4068, 0.4508, 0.5642, 0.6555],\n",
      "         [0.8450, 0.5713, 0.7538, 0.6011],\n",
      "         [0.3408, 0.4153, 0.4413, 0.5632]],\n",
      "\n",
      "        [[0.8450, 0.3464, 0.9190, 0.5332],\n",
      "         [0.4388, 0.5159, 0.8789, 0.4593],\n",
      "         [0.4034, 0.4455, 0.5629, 0.6555],\n",
      "         [0.8415, 0.5660, 0.7525, 0.6012],\n",
      "         [0.3373, 0.4099, 0.4400, 0.5633]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4090, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4053, 2.2054, 2.0568, 2.4036, 1.8947],\n",
      "        [2.4011, 2.2009, 2.0525, 2.3986, 1.8903],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4157, 0.4534, 0.4862, 0.4160, 0.5278],\n",
      "        [0.4165, 0.4544, 0.4872, 0.4169, 0.5290],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8539, 0.3554, 0.9217, 0.5296],\n",
      "         [0.4477, 0.5249, 0.8815, 0.4557],\n",
      "         [0.4123, 0.4545, 0.5655, 0.6518],\n",
      "         [0.8504, 0.5750, 0.7551, 0.5975],\n",
      "         [0.3462, 0.4189, 0.4426, 0.5596]],\n",
      "\n",
      "        [[0.8491, 0.3530, 0.9206, 0.5330],\n",
      "         [0.4429, 0.5225, 0.8805, 0.4591],\n",
      "         [0.4075, 0.4521, 0.5644, 0.6552],\n",
      "         [0.8456, 0.5726, 0.7541, 0.6009],\n",
      "         [0.3414, 0.4165, 0.4415, 0.5630]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5308],\n",
      "         [0.4457, 0.5268, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8455, 0.3463, 0.9192, 0.5333],\n",
      "         [0.4393, 0.5158, 0.8791, 0.4594],\n",
      "         [0.4039, 0.4454, 0.5631, 0.6556],\n",
      "         [0.8421, 0.5659, 0.7527, 0.6012],\n",
      "         [0.3378, 0.4099, 0.4402, 0.5633]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4090, 2.2085, 2.0589, 2.4075, 1.8969],\n",
      "        [2.4061, 2.2063, 2.0575, 2.4045, 1.8955],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4015, 2.2012, 2.0528, 2.3991, 1.8906]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4156, 0.4533, 0.4860, 0.4159, 0.5276],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4164, 0.4543, 0.4871, 0.4168, 0.5289]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8509, 0.3580, 0.9211, 0.5315],\n",
      "         [0.4447, 0.5275, 0.8810, 0.4576],\n",
      "         [0.4093, 0.4571, 0.5650, 0.6538],\n",
      "         [0.8475, 0.5776, 0.7546, 0.5994],\n",
      "         [0.3433, 0.4215, 0.4421, 0.5615]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8520, 0.3572, 0.9214, 0.5308],\n",
      "         [0.4458, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4563, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4083, 2.2089, 2.0598, 2.4073, 1.8979],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0595, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4566, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8531, 0.3568, 0.9214, 0.5296],\n",
      "         [0.4469, 0.5263, 0.8813, 0.4557],\n",
      "         [0.4115, 0.4559, 0.5653, 0.6519],\n",
      "         [0.8496, 0.5764, 0.7549, 0.5976],\n",
      "         [0.3454, 0.4204, 0.4424, 0.5597]],\n",
      "\n",
      "        [[0.8520, 0.3572, 0.9214, 0.5308],\n",
      "         [0.4458, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4104, 0.4563, 0.5652, 0.6531],\n",
      "         [0.8486, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8539, 0.3556, 0.9216, 0.5293],\n",
      "         [0.4477, 0.5251, 0.8815, 0.4554],\n",
      "         [0.4122, 0.4547, 0.5655, 0.6516],\n",
      "         [0.8504, 0.5752, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8464, 0.3474, 0.9196, 0.5334],\n",
      "         [0.4402, 0.5169, 0.8794, 0.4595],\n",
      "         [0.4047, 0.4465, 0.5634, 0.6557],\n",
      "         [0.8429, 0.5670, 0.7530, 0.6013],\n",
      "         [0.3387, 0.4110, 0.4405, 0.5634]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4088, 2.2088, 2.0591, 2.4075, 1.8972],\n",
      "        [2.4087, 2.2089, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4026, 2.2023, 2.0538, 2.4002, 1.8917],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4151, 0.4527, 0.4856, 0.4154, 0.5271],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4162, 0.4541, 0.4869, 0.4166, 0.5286],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5989],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7549, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4101, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8502, 0.3588, 0.9209, 0.5318],\n",
      "         [0.4440, 0.5283, 0.8807, 0.4579],\n",
      "         [0.4086, 0.4579, 0.5647, 0.6541],\n",
      "         [0.8467, 0.5784, 0.7544, 0.5997],\n",
      "         [0.3425, 0.4224, 0.4418, 0.5618]],\n",
      "\n",
      "        [[0.8539, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5971],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5592]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4080, 2.2090, 2.0599, 2.4072, 1.8981],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4153, 0.4527, 0.4855, 0.4154, 0.5268],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9213, 0.5309],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4570],\n",
      "         [0.4100, 0.4565, 0.5651, 0.6532],\n",
      "         [0.8482, 0.5770, 0.7548, 0.5988],\n",
      "         [0.3440, 0.4210, 0.4422, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8535, 0.3563, 0.9216, 0.5293],\n",
      "         [0.4473, 0.5257, 0.8814, 0.4554],\n",
      "         [0.4119, 0.4554, 0.5654, 0.6516],\n",
      "         [0.8501, 0.5758, 0.7550, 0.5972],\n",
      "         [0.3458, 0.4198, 0.4425, 0.5593]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0595, 2.4073, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4088, 2.2086, 2.0589, 2.4074, 1.8969]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4856, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8458, 0.3454, 0.9192, 0.5336],\n",
      "         [0.4396, 0.5149, 0.8791, 0.4597],\n",
      "         [0.4042, 0.4445, 0.5631, 0.6559],\n",
      "         [0.8423, 0.5650, 0.7527, 0.6015],\n",
      "         [0.3381, 0.4089, 0.4402, 0.5636]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8538, 0.3557, 0.9216, 0.5293],\n",
      "         [0.4476, 0.5251, 0.8815, 0.4554],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6516],\n",
      "         [0.8504, 0.5752, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4101, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4016, 2.2010, 2.0527, 2.3990, 1.8905],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4164, 0.4543, 0.4872, 0.4168, 0.5290],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1807, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8513, 0.3577, 0.9213, 0.5312],\n",
      "         [0.4451, 0.5272, 0.8811, 0.4573],\n",
      "         [0.4097, 0.4568, 0.5651, 0.6535],\n",
      "         [0.8479, 0.5773, 0.7547, 0.5991],\n",
      "         [0.3437, 0.4212, 0.4422, 0.5613]],\n",
      "\n",
      "        [[0.8521, 0.3572, 0.9214, 0.5308],\n",
      "         [0.4459, 0.5267, 0.8813, 0.4568],\n",
      "         [0.4104, 0.4563, 0.5653, 0.6530],\n",
      "         [0.8486, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3444, 0.4207, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8483, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5308],\n",
      "         [0.4457, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5988],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5609]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4087, 2.2089, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8522, 0.3572, 0.9215, 0.5306],\n",
      "         [0.4460, 0.5266, 0.8813, 0.4567],\n",
      "         [0.4106, 0.4563, 0.5653, 0.6529],\n",
      "         [0.8487, 0.5767, 0.7549, 0.5986],\n",
      "         [0.3445, 0.4207, 0.4424, 0.5607]],\n",
      "\n",
      "        [[0.8535, 0.3564, 0.9215, 0.5292],\n",
      "         [0.4473, 0.5259, 0.8814, 0.4553],\n",
      "         [0.4119, 0.4555, 0.5653, 0.6515],\n",
      "         [0.8500, 0.5760, 0.7550, 0.5971],\n",
      "         [0.3458, 0.4200, 0.4424, 0.5592]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8532, 0.3567, 0.9215, 0.5296],\n",
      "         [0.4470, 0.5262, 0.8813, 0.4557],\n",
      "         [0.4115, 0.4558, 0.5653, 0.6519],\n",
      "         [0.8497, 0.5763, 0.7549, 0.5975],\n",
      "         [0.3455, 0.4203, 0.4424, 0.5596]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4087, 2.2090, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4088, 2.2086, 2.0589, 2.4074, 1.8969],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4088, 2.2087, 2.0591, 2.4075, 1.8971],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4527, 0.4857, 0.4154, 0.5271],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3576, 0.9213, 0.5311],\n",
      "         [0.4453, 0.5271, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4567, 0.5651, 0.6534],\n",
      "         [0.8480, 0.5772, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4211, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8505, 0.3604, 0.9211, 0.5306],\n",
      "         [0.4443, 0.5299, 0.8810, 0.4567],\n",
      "         [0.4089, 0.4595, 0.5649, 0.6529],\n",
      "         [0.8471, 0.5800, 0.7546, 0.5985],\n",
      "         [0.3428, 0.4240, 0.4420, 0.5606]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4100, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8482, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3440, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4083, 2.2095, 2.0601, 2.4077, 1.8983],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4526, 0.4854, 0.4153, 0.5268],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8523, 0.3571, 0.9215, 0.5306],\n",
      "         [0.4461, 0.5265, 0.8813, 0.4567],\n",
      "         [0.4107, 0.4562, 0.5653, 0.6529],\n",
      "         [0.8488, 0.5766, 0.7549, 0.5985],\n",
      "         [0.3446, 0.4206, 0.4424, 0.5606]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8520, 0.3572, 0.9214, 0.5308],\n",
      "         [0.4458, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4104, 0.4563, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5987],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5608]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4087, 2.2089, 2.0595, 2.4075, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0595, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4856, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8471, 0.3490, 0.9199, 0.5334],\n",
      "         [0.4409, 0.5184, 0.8797, 0.4595],\n",
      "         [0.4054, 0.4481, 0.5637, 0.6557],\n",
      "         [0.8436, 0.5685, 0.7533, 0.6013],\n",
      "         [0.3394, 0.4125, 0.4408, 0.5634]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8538, 0.3557, 0.9216, 0.5292],\n",
      "         [0.4476, 0.5252, 0.8815, 0.4553],\n",
      "         [0.4122, 0.4548, 0.5655, 0.6515],\n",
      "         [0.8504, 0.5753, 0.7551, 0.5972],\n",
      "         [0.3462, 0.4192, 0.4426, 0.5593]],\n",
      "\n",
      "        [[0.8514, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4452, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8455, 0.3463, 0.9192, 0.5333],\n",
      "         [0.4393, 0.5158, 0.8791, 0.4594],\n",
      "         [0.4039, 0.4454, 0.5631, 0.6556],\n",
      "         [0.8420, 0.5659, 0.7527, 0.6012],\n",
      "         [0.3378, 0.4098, 0.4401, 0.5633]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4036, 2.2034, 2.0549, 2.4014, 1.8928],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2085, 2.0588, 2.4074, 1.8968],\n",
      "        [2.4084, 2.2089, 2.0596, 2.4073, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4015, 2.2012, 2.0528, 2.3990, 1.8906]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4160, 0.4538, 0.4866, 0.4164, 0.5283],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4164, 0.4543, 0.4871, 0.4168, 0.5289]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4100, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7549, 0.5989],\n",
      "         [0.3439, 0.4209, 0.4423, 0.5610]],\n",
      "\n",
      "        [[0.8500, 0.3620, 0.9210, 0.5302],\n",
      "         [0.4438, 0.5315, 0.8808, 0.4563],\n",
      "         [0.4083, 0.4611, 0.5648, 0.6525],\n",
      "         [0.8465, 0.5816, 0.7545, 0.5981],\n",
      "         [0.3423, 0.4256, 0.4419, 0.5602]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8481, 0.3511, 0.9202, 0.5333],\n",
      "         [0.4419, 0.5206, 0.8801, 0.4594],\n",
      "         [0.4065, 0.4502, 0.5641, 0.6556],\n",
      "         [0.8446, 0.5707, 0.7537, 0.6012],\n",
      "         [0.3404, 0.4146, 0.4412, 0.5633]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4457, 0.5268, 0.8812, 0.4570],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8485, 0.5769, 0.7548, 0.5988],\n",
      "         [0.3442, 0.4209, 0.4423, 0.5609]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4081, 2.2097, 2.0602, 2.4077, 1.8985],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4049, 2.2049, 2.0563, 2.4031, 1.8943],\n",
      "        [2.4086, 2.2090, 2.0596, 2.4075, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4153, 0.4525, 0.4854, 0.4153, 0.5267],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4158, 0.4535, 0.4863, 0.4161, 0.5279],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([256, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4457, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8516, 0.3574, 0.9213, 0.5309],\n",
      "         [0.4454, 0.5269, 0.8812, 0.4570],\n",
      "         [0.4100, 0.4565, 0.5651, 0.6532],\n",
      "         [0.8482, 0.5770, 0.7548, 0.5988],\n",
      "         [0.3440, 0.4210, 0.4422, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8537, 0.3558, 0.9216, 0.5294],\n",
      "         [0.4475, 0.5253, 0.8815, 0.4555],\n",
      "         [0.4121, 0.4549, 0.5654, 0.6517],\n",
      "         [0.8502, 0.5754, 0.7551, 0.5973],\n",
      "         [0.3460, 0.4194, 0.4425, 0.5594]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5308],\n",
      "         [0.4457, 0.5267, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8485, 0.5768, 0.7549, 0.5988],\n",
      "         [0.3443, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4098, 0.4565, 0.5652, 0.6534],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5310],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4571],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8481, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([256, 5]) tensor([[2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4084, 2.2088, 2.0595, 2.4073, 1.8976],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4089, 2.2086, 2.0589, 2.4075, 1.8969],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([256, 5]) tensor([[0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4856, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4151, 0.4528, 0.4857, 0.4154, 0.5272],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([256, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 0 >>>   tensor([[[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]],\n",
      "\n",
      "        [[0.1409, 0.6232, 0.0770, 0.4540],\n",
      "         [0.5471, 0.4537, 0.1171, 0.5279],\n",
      "         [0.5825, 0.5241, 0.4331, 0.3317],\n",
      "         [0.1443, 0.4036, 0.2435, 0.3860],\n",
      "         [0.6486, 0.5596, 0.5561, 0.4239]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([16, 5, 4]) torch.Size([5, 4])\n",
      " 1 >>>   tensor([[[0.8479, 0.3506, 0.9202, 0.5333],\n",
      "         [0.4417, 0.5201, 0.8800, 0.4594],\n",
      "         [0.4063, 0.4497, 0.5640, 0.6556],\n",
      "         [0.8444, 0.5702, 0.7536, 0.6012],\n",
      "         [0.3402, 0.4142, 0.4411, 0.5633]],\n",
      "\n",
      "        [[0.8493, 0.3535, 0.9207, 0.5328],\n",
      "         [0.4431, 0.5230, 0.8805, 0.4589],\n",
      "         [0.4077, 0.4526, 0.5645, 0.6551],\n",
      "         [0.8459, 0.5731, 0.7542, 0.6008],\n",
      "         [0.3417, 0.4170, 0.4416, 0.5629]],\n",
      "\n",
      "        [[0.8515, 0.3575, 0.9213, 0.5311],\n",
      "         [0.4453, 0.5270, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4566, 0.5652, 0.6534],\n",
      "         [0.8481, 0.5771, 0.7548, 0.5990],\n",
      "         [0.3439, 0.4211, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8515, 0.3574, 0.9214, 0.5311],\n",
      "         [0.4453, 0.5269, 0.8812, 0.4572],\n",
      "         [0.4099, 0.4565, 0.5652, 0.6533],\n",
      "         [0.8480, 0.5770, 0.7548, 0.5990],\n",
      "         [0.3438, 0.4210, 0.4423, 0.5611]],\n",
      "\n",
      "        [[0.8519, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4457, 0.5268, 0.8813, 0.4569],\n",
      "         [0.4103, 0.4564, 0.5652, 0.6531],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3442, 0.4208, 0.4423, 0.5609]],\n",
      "\n",
      "        [[0.8515, 0.3577, 0.9213, 0.5312],\n",
      "         [0.4453, 0.5272, 0.8811, 0.4573],\n",
      "         [0.4098, 0.4568, 0.5651, 0.6535],\n",
      "         [0.8480, 0.5773, 0.7547, 0.5991],\n",
      "         [0.3438, 0.4212, 0.4422, 0.5612]],\n",
      "\n",
      "        [[0.8456, 0.3459, 0.9192, 0.5334],\n",
      "         [0.4394, 0.5154, 0.8791, 0.4595],\n",
      "         [0.4040, 0.4450, 0.5630, 0.6557],\n",
      "         [0.8421, 0.5655, 0.7527, 0.6013],\n",
      "         [0.3379, 0.4094, 0.4401, 0.5634]],\n",
      "\n",
      "        [[0.8518, 0.3573, 0.9214, 0.5309],\n",
      "         [0.4456, 0.5268, 0.8813, 0.4570],\n",
      "         [0.4102, 0.4564, 0.5652, 0.6532],\n",
      "         [0.8484, 0.5769, 0.7549, 0.5988],\n",
      "         [0.3441, 0.4209, 0.4423, 0.5609]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 2 >>>   torch.Size([16, 5]) tensor([[2.4046, 2.2046, 2.0560, 2.4027, 1.8940],\n",
      "        [2.4064, 2.2066, 2.0578, 2.4048, 1.8958],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8978],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4085, 2.2089, 2.0596, 2.4074, 1.8977],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977],\n",
      "        [2.4085, 2.2090, 2.0597, 2.4074, 1.8978],\n",
      "        [2.4015, 2.2011, 2.0527, 2.3990, 1.8905],\n",
      "        [2.4086, 2.2089, 2.0596, 2.4075, 1.8977]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 3 >>>   torch.Size([16, 5]) tensor([[0.4159, 0.4536, 0.4864, 0.4162, 0.5280],\n",
      "        [0.4156, 0.4532, 0.4860, 0.4158, 0.5275],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5269],\n",
      "        [0.4164, 0.4543, 0.4872, 0.4168, 0.5290],\n",
      "        [0.4152, 0.4527, 0.4855, 0.4154, 0.5270]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      " 4 >>> calc_q_ij q_i shape  torch.Size([16, 5]) tensor([[0.1808, 0.1972, 0.2115, 0.1810, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1810, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1809, 0.1972, 0.2115, 0.1809, 0.2295],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2296],\n",
      "        [0.1808, 0.1972, 0.2115, 0.1809, 0.2295]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "res= dec_obj.get_cluster(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1000,  0.2500],\n",
       "        [-0.2500, -1.0000]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = FT(np.array( [[0.1,0.25],[-0.25,-1]]))\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3500, 0.7500],\n",
       "         [0.3500, 0.7500]],\n",
       "\n",
       "        [[2.5000, 1.5000],\n",
       "         [2.5000, 1.5000]],\n",
       "\n",
       "        [[6.0500, 7.0500],\n",
       "         [6.0500, 7.0500]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = FT( np.array(\n",
    "    [\n",
    "        [0.35,0.75],\n",
    "        [2.50,1.50],\n",
    "        [6.05,7.05]\n",
    "    ]\n",
    "))\n",
    "\n",
    "b1 = b.repeat([1,2]).reshape([-1,2,2])\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2500, -0.5000],\n",
       "         [-0.6000, -1.7500]],\n",
       "\n",
       "        [[-2.4000, -1.2500],\n",
       "         [-2.7500, -2.5000]],\n",
       "\n",
       "        [[-5.9500, -6.8000],\n",
       "         [-6.3000, -8.0500]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = LT(\n",
    "[[0,1],[1,0],[0,1]]\n",
    ")\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a -b1\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [1, 1]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.repeat(1,1,2).reshape([-1,2,2]).permute([0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.0000],\n",
       "         [-0.6000, -1.7500]],\n",
       "\n",
       "        [[-2.4000, -1.2500],\n",
       "         [-0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.0000, -0.0000],\n",
       "         [-6.3000, -8.0500]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.repeat(1,1,2).reshape([-1,2,2]).permute([0,2,1]) *  c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f27ee0a63d0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f27ee0a6910>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f27ee0a6e50>,\n",
       "  <matplotlib.lines.Line2D at 0x7f27ee0cb3d0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f27ee094e50>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f27ee0cb950>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f27ee0cbe90>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_obj."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
