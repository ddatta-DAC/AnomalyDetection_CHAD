{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./..')\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "import argparse\n",
    "import re\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "CONFIG = None\n",
    "DIR_LOC = None\n",
    "CONFIG = None\n",
    "CONFIG_FILE = 'config.yaml'\n",
    "ID_COL = 'PanjivaRecordID'\n",
    "categorical_columns = None\n",
    "use_cols = None\n",
    "freq_bound = None\n",
    "save_dir = None\n",
    "categorical_columns = None\n",
    "numeric_columns = None\n",
    "\n",
    "# ----------------------\n",
    "# Scale features\n",
    "# ----------------------\n",
    "def set_up_config(_DIR=None):\n",
    "    global DIR\n",
    "    global CONFIG\n",
    "    global CONFIG_FILE\n",
    "    global use_cols\n",
    "    global num_neg_samples_ape\n",
    "    global save_dir\n",
    "    global column_value_filters\n",
    "    global num_neg_samples\n",
    "    global DATA_SOURCE \n",
    "    global ID_COL\n",
    "    global numeric_columns\n",
    "    global categorical_columns, numeric_columns\n",
    "    \n",
    "    with open(CONFIG_FILE) as f:\n",
    "        CONFIG = yaml.safe_load(f)\n",
    "\n",
    "    if _DIR is not None:\n",
    "        DIR = _DIR\n",
    "        CONFIG['DIR'] = _DIR\n",
    "    else:\n",
    "        DIR = CONFIG['DIR']\n",
    "    numeric_columns = list(sorted(CONFIG['numeric_columns']))\n",
    "    categorical_columns = list(sorted(CONFIG['categorical_columns']))\n",
    "    ID_COL = 'PanjivaRecordID'\n",
    "    DIR_LOC = re.sub('[0-9]', '', DIR)\n",
    "#     DATA_SOURCE = os.path.join(DATA_SOURCE, DIR_LOC)\n",
    "    save_dir = CONFIG['save_dir']\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    save_dir = os.path.join(\n",
    "        CONFIG['save_dir'],\n",
    "        DIR\n",
    "    )\n",
    "    DATA_SOURCE = save_dir\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    use_cols = [ID_COL] + categorical_columns +  numeric_columns\n",
    "    freq_bound_PERCENTILE = CONFIG['freq_bound_PERCENTILE']\n",
    "    freq_bound_ABSOLUTE = CONFIG['freq_bound_ABSOLUTE']\n",
    "    column_value_filters = CONFIG[DIR]['column_value_filters']\n",
    "\n",
    "    _cols = list(use_cols)\n",
    "    _cols.remove(ID_COL)\n",
    "    attribute_columns = categorical_columns +  numeric_columns    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_transform(DIR):\n",
    "    global categorical_columns, numeric_columns\n",
    "    global DATA_SOURCE\n",
    "    \n",
    "    train_data = pd.read_csv(os.path.join(DATA_SOURCE, 'train_data.csv'))\n",
    "    test_data = pd.read_csv(os.path.join(DATA_SOURCE, 'test_data.csv'))\n",
    "    \n",
    "    for num in numeric_columns:\n",
    "        scaler_obj = MinMaxScaler()\n",
    "        scaler_obj.fit( train_data[num].values.reshape(-1,1))\n",
    "        train_data.loc[:,num] = scaler_obj.transform(train_data[num].values.reshape(-1,1)).reshape(-1)\n",
    "        test_data.loc[:,num] = scaler_obj.transform(test_data[num].values.reshape(-1,1)).reshape(-1)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "#  generate one hot version \n",
    "# -------------------------------\n",
    "def create_oneHot_version( df ):\n",
    "    global categorical_columns, numeric_columns, ID_COL\n",
    "    df1 = df.copy(deep=True) \n",
    "    \n",
    "    for cc in categorical_columns:\n",
    "        print(cc)\n",
    "        df1 = pd.get_dummies(\n",
    "            df1, columns = [cc],\n",
    "            drop_first = False\n",
    "        )\n",
    "    \n",
    "    all_columns = list(df1.columns)\n",
    "    disc_columns = [ c for c in all_columns if c not in numeric_columns and c != ID_COL]\n",
    "    ord_cols = [ID_COL]  + disc_columns + numeric_columns \n",
    "    return df1[ord_cols]\n",
    "\n",
    "def process():\n",
    "    train_data_scaled, test_data_scaled =  feature_transform(DIR)\n",
    "    train_scaled_01 = create_oneHot_version( train_data_scaled )\n",
    "    test_scaled_01 = create_oneHot_version( test_data_scaled )\n",
    "\n",
    "    # ------------------\n",
    "    # Save data\n",
    "    # ------------------\n",
    "\n",
    "    train_data_scaled.to_csv(os.path.join(save_dir, 'train_data_scaled.csv'), index_col=None)\n",
    "    test_data_scaled.to_csv(os.path.join(save_dir, 'test_data_scaled.csv'), index_col=None)\n",
    "    train_scaled_01.to_csv(os.path.join(save_dir, 'test_scaled_01.csv'), index_col=None)\n",
    "    test_scaled_01.to_csv(os.path.join(save_dir, 'test_scaled_01.csv'), index_col=None)\n",
    "\n",
    "args = parser.parse_args()\n",
    "DIR = args.DIR\n",
    "# -------------------------------- #\n",
    "set_up_config(args.DIR)\n",
    "process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
