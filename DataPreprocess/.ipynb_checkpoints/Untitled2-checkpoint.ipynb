{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import re\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dims = None\n",
    "DIR = None\n",
    "\n",
    "CONFIG = None\n",
    "CONFIG_FILE = 'config.yaml'\n",
    "ID_COL = 'PanjivaRecordID'\n",
    "categorical_columns = None\n",
    "use_cols = None\n",
    "freq_bound = None\n",
    "save_dir = None\n",
    "categorical_columns = None\n",
    "numeric_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Scale features\n",
    "# ----------------------\n",
    "def set_up_config(_DIR=None):\n",
    "    global DIR\n",
    "    global CONFIG\n",
    "    global CONFIG_FILE\n",
    "    global use_cols\n",
    "    global num_neg_samples_ape\n",
    "    global save_dir\n",
    "    global column_value_filters\n",
    "    global num_neg_samples\n",
    "    global DATA_SOURCE \n",
    "    global ID_COL\n",
    "    global numeric_columns\n",
    "    global categorical_columns, numeric_columns\n",
    "    \n",
    "    with open(CONFIG_FILE) as f:\n",
    "        CONFIG = yaml.safe_load(f)\n",
    "\n",
    "    if _DIR is not None:\n",
    "        DIR = _DIR\n",
    "        CONFIG['DIR'] = _DIR\n",
    "    else:\n",
    "        DIR = CONFIG['DIR']\n",
    "    numeric_columns = list(sorted(CONFIG['numeric_columns']))\n",
    "    categorical_columns = list(sorted(CONFIG['categorical_columns']))\n",
    "    ID_COL = 'PanjivaRecordID'\n",
    "    DIR_LOC = re.sub('[0-9]', '', DIR)\n",
    "#     DATA_SOURCE = os.path.join(DATA_SOURCE, DIR_LOC)\n",
    "    save_dir = CONFIG['save_dir']\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    save_dir = os.path.join(\n",
    "        CONFIG['save_dir'],\n",
    "        DIR\n",
    "    )\n",
    "    DATA_SOURCE = save_dir\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    use_cols = [ID_COL] + categorical_columns +  numeric_columns\n",
    "    freq_bound_PERCENTILE = CONFIG['freq_bound_PERCENTILE']\n",
    "    freq_bound_ABSOLUTE = CONFIG['freq_bound_ABSOLUTE']\n",
    "    column_value_filters = CONFIG[DIR]['column_value_filters']\n",
    "\n",
    "    _cols = list(use_cols)\n",
    "    _cols.remove(ID_COL)\n",
    "    attribute_columns = categorical_columns +  numeric_columns    \n",
    "    get_domain_dims()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_dims():\n",
    "    global DIR\n",
    "    global save_dir\n",
    "    global domain_dims\n",
    "    with open(os.path.join(save_dir, 'domain_dims.pkl'),'rb') as fh:\n",
    "        domain_dims = pickle.load(fh)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_oneHot_version( df ):\n",
    "    global categorical_columns, numeric_columns, ID_COL\n",
    "    df1 = df.copy(deep=True) \n",
    "    \n",
    "    for cc in categorical_columns:\n",
    "        print(cc)\n",
    "        df1 = pd.get_dummies(\n",
    "            df1, columns = [cc],\n",
    "            drop_first = False\n",
    "        )\n",
    "    \n",
    "    all_columns = list(df1.columns)\n",
    "    disc_columns = [ c for c in all_columns if c not in numeric_columns and c != ID_COL]\n",
    "    ord_cols = [ID_COL]  + disc_columns + numeric_columns \n",
    "    return df1[ord_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_row(\n",
    "    row, \n",
    "    perturb_cat_cols = 2, \n",
    "    perturb_numeric_cols = 1 \n",
    "):\n",
    "    global categorical_columns, numeric_columns, domain_dims\n",
    "  \n",
    "    row = row.copy()\n",
    "    pert_cat_cols = np.random.choice( \n",
    "        categorical_columns, \n",
    "        size = perturb_cat_cols, \n",
    "        replace = False\n",
    "    )\n",
    "    \n",
    "    for col in pert_cat_cols:\n",
    "        row[col] = np.random.choice(np.arange(domain_dims[col], dtype=int ), 1)\n",
    "    \n",
    "    # Select a numeric column \n",
    "    \n",
    "    numeric_cols = np.random.choice( numeric_columns , size = perturb_numeric_cols, replace = False)\n",
    "    for nc in numeric_cols:\n",
    "        val = row[nc]\n",
    "        if val < 0.5:\n",
    "            val += np.random.uniform(0.25,0.75) \n",
    "        else:\n",
    "            val -= np.random.uniform(0.25,0.75) \n",
    "        row[nc] = val\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up_config('us_import1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandarallel/pandarallel.py\", line 59, in global_worker\n    return _func(x)\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandarallel/pandarallel.py\", line 111, in wrapper\n    **kwargs\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n    return df.apply(func, *args, **kwargs)\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandas/core/frame.py\", line 6878, in apply\n    return op.get_result()\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandas/core/apply.py\", line 186, in get_result\n    return self.apply_standard()\n  File \"/home/ddatta/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandas/core/apply.py\", line 296, in apply_standard\n    values, self.f, axis=self.axis, dummy=dummy, labels=labels\n  File \"pandas/_libs/reduction.pyx\", line 620, in pandas._libs.reduction.compute_reduction\n  File \"pandas/_libs/reduction.pyx\", line 128, in pandas._libs.reduction.Reducer.get_result\n  File \"<ipython-input-36-4d9d0b80249b>\", line 24, in perturb_row\n    val += random.uniform(0.25,0.75)\nNameError: name 'random' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e81defffd1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_data_scaled.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mperturb_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0minput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0moutput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mmap_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AD_v2/lib/python3.6/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mprogress_bars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogresses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     return (\n",
      "\u001b[0;32m~/anaconda3/envs/AD_v2/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(os.path.join(save_dir, 'test_data_scaled.csv') ).head(100)\n",
    "anomalies = test_data.parallel_apply( perturb_row, axis= 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
